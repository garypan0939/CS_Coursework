{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Data Processing\n",
    "\n",
    "## Task 1\n",
    "This coursework will assess your understanding of using NoSQL to store and retrieve data.  You will perform operations on data from the Enron email dataset in a MongoDB database, and write a report detailing the suitability of different types of databases for data science applications.  You will be required to run code to answer the given questions in the Jupyter notebook provided, and write a report describing alternative approaches to using MongoDB.\n",
    "\n",
    "Download the JSON version of the Enron data (using the “Download as zip” to download the data file from http://edshare.soton.ac.uk/19548/, the file is about 380MB) and import into a collection called messages in a database called enron.  You do not need to set up any authentication.  In the Jupyter notebook provided, perform the following tasks, using the Python PyMongo library.\n",
    "\n",
    "Answers should be efficient in terms of speed.  Answers which are less efficient will not get full marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12T16:36:09.716+0000\tconnected to: localhost\n",
      "2019-12-12T16:36:09.716+0000\tdropping: enron.messages\n",
      "2019-12-12T16:36:12.715+0000\t[##......................] enron.messages\t43.2MB/354MB (12.2%)\n",
      "2019-12-12T16:36:15.720+0000\t[#####...................] enron.messages\t87.2MB/354MB (24.6%)\n",
      "2019-12-12T16:36:18.715+0000\t[#########...............] enron.messages\t136MB/354MB (38.5%)\n",
      "2019-12-12T16:36:21.715+0000\t[############............] enron.messages\t187MB/354MB (52.8%)\n",
      "2019-12-12T16:36:24.716+0000\t[################........] enron.messages\t238MB/354MB (67.4%)\n",
      "2019-12-12T16:36:27.723+0000\t[###################.....] enron.messages\t284MB/354MB (80.2%)\n",
      "2019-12-12T16:36:30.719+0000\t[######################..] enron.messages\t329MB/354MB (92.9%)\n",
      "2019-12-12T16:36:32.687+0000\t[########################] enron.messages\t354MB/354MB (100.0%)\n",
      "2019-12-12T16:36:32.687+0000\timported 100000 documents\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 100000 messages.json > messages_short.json\n",
    "mongoimport --db enron --collection messages --drop --file messages_short.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "Write a function which returns a MongoDB connection object to the \"messages\" collection. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_collection",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_collection():\n",
    "    \"\"\"\n",
    "    Connects to the server, and returns a collection object\n",
    "    of the `messages` collection in the `enron` database\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE    \n",
    "    #client = MongoClient('mongodb://localhost:127.0.1')\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    #print client.list_database_names()\n",
    "    db = client.enron\n",
    "    collection = db.messages\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e27'),\n",
      " u'body': u\"the scrimmage is still up in the air...\\n\\n\\nwebb said that they didnt want to scrimmage...\\n\\nthe aggies  are scrimmaging each other... (the aggie teams practiced on \\nSunday)\\n\\nwhen I called the aggie captains to see if we could use their field.... they \\nsaid that it was tooo smalll for us to use...\\n\\n\\nsounds like bullshit to me... but what can we do....\\n\\n\\nanyway... we will have to do another practice Wed. night....    and I dont' \\nknow where we can practice.... any suggestions...\\n\\n\\nalso,  we still need one  more person...\",\n",
      " u'filename': u'450.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 08:22:00 -0800 (PST)',\n",
      "              u'From': u'michael.simmons@enron.com',\n",
      "              u'Message-ID': u'<6884142.1075854677416.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'Re: Plays and other information',\n",
      "              u'To': u'eric.bass@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Michael Simmons',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Eric Bass',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e29'),\n",
      " u'body': u\"I'm ready, are you?  Did you get my message about Dad?  I don't want you to\\nworry but he will have to be in bed with his leg elevated for a week.  Send\\nhim a nice note, o.k?\\n----- Original Message -----\\nFrom: <Eric.Bass@enron.com>\\nTo: <shusser@enron.com>; <dfranklin@hanovermeasurement.com>;\\n<Jason.Bass2@COMPAQ.com>; <daphneco64@bigplanet.com>;\\n<lwbthemarine@bigplanet.com>\\nSent: Tuesday, November 14, 2000 3:09 PM\\nSubject: check it out\\n\\n\\n> http://www.telski.com/tandp/extras/photo_of_day/index.html\\n>\",\n",
      " u'filename': u'452.',\n",
      " u'headers': {u'Bcc': u'jason.bass2@compaq.com',\n",
      "              u'Cc': u'jason.bass2@compaq.com',\n",
      "              u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 07:25:00 -0800 (PST)',\n",
      "              u'From': u'daphneco64@bigplanet.com',\n",
      "              u'Message-ID': u'<24383193.1075854677459.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'Re: check it out',\n",
      "              u'To': u'eric.bass@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'\"K. Bass\" <daphneco64@bigplanet.com>',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Eric.Bass@enron.com',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u'\"Bass, Jason\" <Jason.Bass2@COMPAQ.com>'},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e28'),\n",
      " u'body': u'suggestion... make a playbook that just shows individual routes.. that way \\nLuis can just customize  in the huddle....\\n\\nEx.   outs, curls, out-and-up, post..  etc...     \\n\\n\\nalso,,    You give routes to the linemen and they should block  and then roll \\nout into the open flats once the defense goes past.... \\n\\nAND... most importantly.. how did you  draw those plays  excel....\\n\\n',\n",
      " u'filename': u'451.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 07:37:00 -0800 (PST)',\n",
      "              u'From': u'michael.simmons@enron.com',\n",
      "              u'Message-ID': u'<6098626.1075854677438.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'Re: Plays and other information',\n",
      "              u'To': u'eric.bass@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Michael Simmons',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Eric Bass',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2d'),\n",
      " u'body': u'?\\n\\n?http://www.pbcelections.org/Sample%20Ballots/instruct.jpg\\n - instruct.jpg.url',\n",
      " u'filename': u'456.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=ANSI_X3.4-1968',\n",
      "              u'Date': u'Tue, 14 Nov 2000 05:39:00 -0800 (PST)',\n",
      "              u'From': u'daphneco64@bigplanet.com',\n",
      "              u'Message-ID': u'<32712651.1075854677554.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'instruct.jpg',\n",
      "              u'To': u'lwbthemarine@bigplanet.com, jason.bass2@compaq.com, eric.bass@enron.com, \\r\\n\\tchebert108@aol.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'\"K. Bass\" <daphneco64@bigplanet.com>',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'\"Larry W. Bass\" <lwbthemarine@bigplanet.com>, \"Bass, Jason\" <Jason.Bass2@COMPAQ.com>, Eric Bass <Eric.Bass@enron.com>, CHebert108@aol.com',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e30'),\n",
      " u'body': u'DId you talk to Burkhart??  I prefer him but if not, I will ask Mauricio.',\n",
      " u'filename': u'459.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 03:00:00 -0800 (PST)',\n",
      "              u'From': u'luis.mena@enron.com',\n",
      "              u'Message-ID': u'<296353.1075854677622.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'',\n",
      "              u'To': u'eric.bass@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Luis Mena',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Eric Bass',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2a'),\n",
      " u'body': u'I\\'ve had lots of folks ask for more details on the story I reported Monday\\nnight as Denver QB Brian Griese made my \"Downgrade\" list in the \"Upgrades /\\nDowngrade\" article.\\n\\nAccording to John Clayton of ESPN, Griese\\'s shoulder injury is a separation\\nof the AC joint in his right clavicle.  He took a pain killing shot and\\nfinished the game.   Unfortunately, his status for this week\\'s game against\\nSan Diego is in doubt.  At this point, coach Mike Shanahan is saying it will\\nbe a couple of days before they decide what they\\'re doing.\\n\\nI\\'ve copied the entire story below if you\\'d like more details.  Sounds like\\nthis victory could be one of those career turning point games for him.\\nGriese describing how he knew he was about to get slammed in the pocket\\nbecause he could hear the crowd hold it\\'s breath is classic.  I\\'ll keep an\\neye on it for you as this shakes out.\\n\\nJoe\\n\\n\\n\\nFrom the article:  http://espn.go.com/nfl/news/2000/1114/876898.html\\nDENVER -- Brian Griese had a secret. Mike Shanahan knew because he was the\\nhead coach. Griese knew because he had the pain piercing in the middle of\\nhis right shoulder.\\nHis teammates didn\\'t know what went on behind closed doors in Monday\\'s\\ndramatic 27-24 Broncos victory over the Raiders at Mile High Stadium. All\\nhis teammates knew was that he had injured his right shoulder on an\\nill-advised run out of bounds minutes into the first quarter.\\nGriese retreated to the locker room with a trainer but wasn\\'t missed. The\\nRaiders had an 11-play, field-goal drive that lasted six minutes. Teammates\\nsaw Griese trot back to the field, warm up and miss only five plays. They\\ndidn\\'t hear that Griese had separated his right clavicle and AC joint and\\nneeded a pain-deadening shot to finish the final three quarters.\\n\"This is not a game I wanted to miss, and I was going to do anything\\npossible to get in the game and help my team win,\" Griese said. \"I was going\\nto do it. It was just the will to play and the will to win, and I wasn\\'t\\ngoing to come out.\"\\nAn hour after the game, Broncos players were surprised that the man who ran\\ntheir huddle had a busted wing. His performance was John Elway-like for\\ncourage, but it also leaves the Broncos uncertain if they will have Griese\\navailable as a starting quarterback for Sunday\\'s game against the San Diego\\nChargers.\\n\"We won\\'t know for a couple of days the exact extent of the injury, but he\\'s\\nsuch a competitor,\" Shanahan said. \"He\\'s been like that since he\\'s been\\nhere. He wants to play, and sometimes you have to be cautious to make sure\\nhe doesn\\'t further hurt himself. That\\'s the kind of guy he is.\"\\nRod Smith is among the many Broncos who have grown to love this guy. Last\\nyear was different. In the preseason, it was supposed to be Bubby Brister\\'s\\nteam, but Shanahan named Griese the starter. Veterans didn\\'t feel totally\\ncomfortable with him. Griese didn\\'t feel comfortable bossing around a group\\nof players who didn\\'t take to him.\\n\"Brian\\'s the one to lead us,\" Smith said. \"I think it would have hurt him\\nmore just sitting there and watching rather than being out there playing\\nwith the shoulder the way it was. Whatever he does, he doesn\\'t surprise me.\\nHe\\'s the best quarterback in the NFL. I know the Raiders think Rich Gannon\\nis. We think Brian is.\"\\nGriese told his offensive players that he didn\\'t have too much zip on the\\nball. They accepted it as just humility.\\n\"I wasn\\'t throwing the ball as well I have been,\" Griese said. \"Some of the\\nballs just died. At that point, it was just your will to play, your will to\\nwin. I wasn\\'t coming out of the game.\"\\nGriese was 22-of-32 for 221 yards with a separated shoulder. He\\'d throw\\npasses and hear, as well as feel, his shoulder popping in and out.\\n\"I knew there was something wrong with it, but they assured me that I\\ncouldn\\'t do any further damage,\" Griese said. \"It was just whether I could\\nhandle the pain.\"\\nBeing injured didn\\'t make Griese shy away from contact. Several times he\\ntook shots from Raiders defenders that bounced him to the frozen Mile High\\nStadium grass. Once, cornerback Eric Allen charged untouched from the\\nblindside. Griese ducked as Allen hit him shoulder high.\\n\"Believe it or not, the reason I kind of ducked when he came in is that I\\nheard the crowd, and the crowd held their breath and I could hear that,\"\\nGriese said. \"I said to myself, \\'Well, somebody must be ready to hit me.\\' \"\\nTalk about homefield advantage. Griese has never had an injury like this. He\\nhas played two seasons with a torn labrum problem in his shoulder that\\nrequires surgery, but this was much more painful.\\nGriese remembered a pass to Rod Smith along the sideline that was a big\\nplay. He had to make just an arm-through pass. It was agonizing. He threw a\\nskinny post to Ed McCaffrey that left McCaffrey vulnerable to a hit on the\\nchin.\\n\"I apologized to him for that because the ball kind of floated on me and I\\ndidn\\'t have any zip on the ball,\" Griese said.\\nGriese said the feeling of his shoulder popping in and out was different.\\n\"We knew it was something that was hurting him, we knew he was banged up,\"\\nfullback Howard Griffith said. \"That\\'s how it is when you\\'ve got a job to\\ndo.\"\\nStill, the story told after the game amazed them.\\n\\n\\n\\n\\n\\nTo unsubscribe from this group, send an email to:\\ncheatsheets-unsubscribe@egroups.com\\n\\n',\n",
      " u'filename': u'453.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 08:32:00 -0800 (PST)',\n",
      "              u'From': u'bryant@cheatsheets.net',\n",
      "              u'Message-ID': u'<8062419.1075854677483.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'[cheatsheets] Brian Griese Injury',\n",
      "              u'To': u'cheatsheets@egroups.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'\"Joe Bryant\" <bryant@cheatsheets.net>',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'\"Cheatsheets Mailing List\" <cheatsheets@egroups.com>',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2c'),\n",
      " u'body': u\"[IMAGE]\\t\\n\\t\\n\\tAirlines\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t\\n\\t\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t[IMAGE]\\n\\t\\n\\n\\n\\nWeek of November 14, 2000\\nA Weekly Travel Newsletter from  TravelNow.com\\n\\n?\\n\\n\\n\\n\\nDear Eric,  \\nIt's getting colder outside and it seems like winter is here  to stay. To \\noffset the dreary days we've got some wonderful  warm weather escapes for \\nyou! Take off to Greece for a museum  and shopping tour. Spend the holidays \\nat Disneyland or Las Vegas.  Go whale watching in Mexico or take a surprise \\nvacation to Jamaica!  If you need to get away take advantage of our great \\ndeals now!\\n\\n\\n\\n\\n??This Week in Here's the Deal\\n\\n\\n[IMAGE]Hotels  in Orlando, Dallas, and Chicago\\n[IMAGE]New  Year's In Las Vegas\\n[IMAGE]Family  Holiday At Disneyland\\n[IMAGE]Holiday  In Greece\\n[IMAGE]Baja  Whale Watching\\n[IMAGE]TravelTips  - Where's My Luggage?\\n[IMAGE]Love  Surprises? \\n[IMAGE]TravelNews  - The Talk of Travel Town\\n\\n\\n\\n\\n\\n\\n[IMAGE]\\n\\n\\n [IMAGE]\\n\\n\\n\\n SURPRISE JAMAICAN VACATION\\n\\n\\n\\n  4 night all-inclusive stay at one of six resorts in  Jamaica\\nResort is assigned 3 days before departure\\nStarts at $429 per person\\n\\n\\n?More  Info...\\n\\n\\n\\n\\n?\\n[IMAGE][IMAGE]  \\n?\\n  \\n\\n?\\n\\nHotel Deals - Rest Your Body And Mind\\n?\\n\\nDon't forget to make your holiday travel plans in advance, they  book up \\nquickly! Grab a great deal on a hotel,  a cheap rental car, or a low priced \\nairline  ticket while you can!\\n\\nReno - Specially acquired rates at the  Hilton Reno Resort and Casino \\nstarting at $52 per night\\n Dallas - Specially acquired rates  at the Wyndham Anatole Hotel starting at \\n$193 per night\\n Houston - Specially  acquired rates at the Sheraton Houston Brookhollow \\nstarting at $56  per night\\n Chicago  - Specially  acquired rates at the Sofitel Chicago starting at $108 \\nper night\\n Orlando  - Specially  acquired rates at the Caribe Royale Resort Suites & \\nVillas starting  at $109 per night\\n  \\nFor more hotel specials, in other cities,  visit our specials page!\\n*All hotel prices are listed in US Dollars.\\n\\n\\n\\n?\\n  Packable Beverage Bottle \\n\\n\\n\\n\\n[IMAGE]\\n  20  oz. plastic flask with insulated foam sleeve keeps  beverages cool or \\nhot for the journey, packs flat  for the trip home. Sleeve available in \\nassorted  colors. \\n$16.95  \\n  Order  Now!  \\n\\n\\nSearch  for travel related products....\\n\\n?\\n\\n?\\n?\\n\\n?\\n  \\n\\n?\\nLand Package -  Celebrate In Las Vegas\\n?\\n\\n  New Year's In Las Vegas\\n-3 nights accommodations in deluxe hotel and casino\\n-From December 29,2000 to January 1, 2001\\n-Starts at $664 per person \\n\\n\\n\\n?\\n?\\n  \\n\\n?\\nFamily Package -  Be Merry In Disneyland\\n?\\n\\n Family Holiday at Disneyland\\n-4 night package for a family of 4 (2 adults and 2 children  under the age of \\n12)\\n-Includes accommodations, passes to Disneyland and Universal Studios,  and \\nmore\\n-Starts at $1042 for family of 4\\n\\n?\\n?\\n \\n\\n?\\nAir and Land Package -  Stroll Through Greece\\n?\\n\\n Holiday In Greece\\n-5 nights accomodations in Athens\\n-Includes roundtrip airfare, some meals, and museum and shopping  tours \\n-From $819 per person\\n\\n?\\n?\\n  \\n\\n?\\nCruise Package - Whale Watch In Mexico\\n?\\n\\n Baja Whale Watching\\n -7night cruise from Cabo San Lucas\\n-Includes wildlife viewing, whale watching, snorkeling, kayaking,  and more\\n-From $2245 per person\\n \\n\\n?\\n?\\n\\n\\n?\\nBest Seller - Fall In Love On A Cruise\\n?\\n\\n The New Love Boat\\n-7 nights Southern Caribbean cruise\\n-Visit San Juan, Aruba, Venezuela, St. Thomas and more\\n-From $749 per person\\n  \\n\\n?\\n?\\n\\n\\n?\\n[IMAGE][IMAGE]  \\n?\\n[IMAGE]\\n\\n?\\n?\\n?\\n??TravelTips \\n?\\nWhere's My Luggage?\\n?\\n\\nI always make my nametag on my suitcase more noticeable by using  bright \\ncolored paper, ribbon or tape that way I can pick it out  quicker on a \\nturnstile and hopefully others will realize it isn't  theirs. -Mary M-H\\n\\nIf you have any great travel tips, stories, or photos send them  to me and \\nyou might just  see your name in the next issue of Here's The Deal!\\n\\n?\\n?\\n[IMAGE]\\n\\n?\\n?\\n\\n\\n?\\n??TravelTools\\n?\\nLove Surprises?\\n?\\nIt doesn't matter if you're  giving or receiving, surprises are a wonderful \\nthing. If you have  someone you'd like to surprise, but you're short on \\nideas, visit Surprise.com.  They have a large array of gifts broken down by \\npersonality type.  Many interesting items are available! Looking to surprise \\nyourself?  Check out Random.com. This site pulls up random  links for you to \\nenjoy. You could spend hours laughing over the websites  you'll be introduced \\nto. Finally, if you're going on the surprise  Jamaican vacation be sure to \\nvisit the TravelShop  and purchase any travel items you may need. You may be \\nsurprised  at what you find!\\n\\n\\n\\n?\\n?\\n\\n\\n[IMAGE]\\n\\n?\\n?\\n?\\n??TravelNews \\n?\\nThe Talk of Travel Town\\n?\\n\\nStudy finds US airline mergers  make good sense\\n Hotel chains slug it out in  battle of the bed\\nAfter decades of war, tourists  return to Afghanistan\\n\\n?\\n?\\n?\\nRead more about TravelNow.com in our Press  Room. (NASDAQ SC Stock Symbol: \\nTNOW) \\n\\n[IMAGE]\\n\\nForward this deal to a friend and start planning a trip together!  \\n\\nWe would hate for you to miss anything, but if you are not interested  in \\nreceiving Here's The Deal! from TravelNow.com, please  click here to \\nunsubscribe.  \\n\\n------------------------------------------------------------------------------\\n---------------------------------------------------------------------\\nYou are currently subscribed as: ebass@enron.com \\n\\n?\\n?\\n\\n\\nHotels  | Airfare | Car  Rental | Rail | Cruises  | Affiliates  | Contact  Us\\n?\\n\\n?\\n[IMAGE]\",\n",
      " u'filename': u'455.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=ANSI_X3.4-1968',\n",
      "              u'Date': u'Tue, 14 Nov 2000 03:11:00 -0800 (PST)',\n",
      "              u'From': u'customers@travelnow.com',\n",
      "              u'Message-ID': u'<12310096.1075854677532.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u\"Here's The Deal .......... Surprise Jamaican Vacation!\",\n",
      "              u'To': u'ebass@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'\"TravelNow.com\" <customers@travelnow.com>',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'\"ebass@enron.com\" <ebass@enron.com>',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2b'),\n",
      " u'body': u'---------------------- Forwarded by Matthew Lenhart/HOU/ECT on 11/14/2000 \\n02:57 PM ---------------------------\\n\\n\\n\"Tom Lenhart\" <tlenhart@corealty.com> on 11/14/2000 01:46:02 PM\\nTo: <jshana12@hotmail.com>\\ncc: <matthew.lenhart@enron.com>, <debbielatham@realtor.com>, \\n<tclupinski@dpdenver.com>, <llschultz3@aol.com> \\n\\nSubject: Sorry, I keep getting these things.\\n\\n\\n\\n\\n-----Original Message-----\\nFrom: Brenda Mosley [mailto:bmosley@corealty.com]\\nSent: Tuesday, November 14, 2000 1:13 PM\\nTo: Tambra Lupinski; Tom Lenhart; J\\'Shana Farley; Annette Williams;\\nMonica Rene Quinn\\nSubject: FW: FW: THIS IS SCARY!!! DO IT!!\\n\\n\\n\\n\\n-----Original Message-----\\nFrom: Franklin, Niecie [mailto:Niecie.Franklin@marriott.com]\\nSent: Tuesday, November 14, 2000 10:18 AM\\nTo: bmosley@corealty.com; mreneq456@aol.com; Brandy Sawyer; Carla\\nColeman; Chris Maston; Jennifer Kadel; Kevin Duncan; Lila MacKinney;\\nPeter Gerling; Shauna Betschart; Tricia Fox; Virginia Glavan\\nSubject: FW: FW: THIS IS SCARY!!! DO IT!!\\n\\n\\n\\n\\n-----Original Message-----\\nFrom: Shawn_Grandberry@r1.fws.gov [mailto:Shawn_Grandberry@r1.fws.gov]\\nSent: Tuesday, November 14, 2000 9:35 AM\\nTo: ddarmstrong16@hotmail.com; Boyd.Nyle@broadband.att.com;\\nQXIO@AOL.COM; zoltan_chancy@hotmail.com; jaymeson@blackplanet.com;\\nZanetha.Evans@Notes.airtouch.com; nannysasa@aol.com;\\nNiecie.Franklin@marriott.com; lhibbert@usa.net; phadrea_ponds@usgs.gov\\nSubject: Fwd: FW: THIS IS SCARY!!! DO IT!!\\n\\n\\n\\nWhy Not receive Junk Mail\\n\\nSubject:    THIS IS SCARY!!! DO IT!!\\n\\n    > >\\n    > The Phone Will  Ring Right After You Do This. . .\\n    > Just read the  little stories and make a wish.\\n    > Scroll all the  way to the bottom and there is\\n    > alittle\\n    > message\\n    > there -then\\n    > do  it. No attachment on this one.\\n    >\\n    >\\n    > I\\'m 13 years  old, and I wished that my dad would\\n    > come\\n    > home from  the army,\\n    > because he\\'d  been having problems with his heart\\n    > and\\n    > right leg. It  was\\n    > 2:53 p.m.\\n    > that  I\\'d made the wish. At 3:07 p.m. (14\\n    > minutes\\n    > later),  the\\n    > doorbell rang,  and there he was,\\n    > luggage and all!!\\n    > Katie\\n    >\\n    >\\n    > I\\'m 20 and I\\'ve  been having trouble in my job and\\n    > on\\n    > the verge of quitting.\\n    > I made\\n    > a simple  wish that my boss would get a new job.\\n    > That was a  1:35\\n    > and at\\n    > 2:55  there was\\n    > an announcement that he was\\n    > promoted.\\n    > Lisa\\n    >\\n    >\\n    > Believe me...  this really works!! Just scroll down\\n    > to\\n    > the end,  but while you do,  make a wish.\\n    > Whatever age you are, is\\n    > the number of  minutes it\\n    > will take for  your wish to come true (ex.\\n    > you are\\n    > 15 years old, it  will take 15 minutes for  your wish to come\\n    > true). If you don\\'t send this to people in 5  minutes, you\\n    > will have\\n    > bad luck for years!!\\n    > Go!!!!!!\\n    > *\\n    > **\\n    > ***\\n    > ****\\n    > *****\\n    > ******\\n    > *******\\n    > ********\\n    > *********\\n    > **********\\n    > ***********\\n    >\\n    > ************\\n    > *************\\n    > **************\\n    > ***************\\n    > ****************\\n    >\\n    > *****************\\n    > ******************\\n    > *******************\\n    > ********************\\n    > *********************\\n    > **********************\\n    > ***********************\\n    > ************************\\n    >\\n    > *************************\\n    > **************************\\n    >\\n    > ***************************\\n    > ****************************\\n    >\\n    > *****************************\\n    > ******************************\\n    >\\n    > *******************************\\n    > ********************************\\n    >\\n    > *********************************\\n    > **********************************\\n    >\\n    > ***********************************\\n    > **********************************\\n    >\\n    > *********************************\\n    > ********************************\\n    >\\n    > *******************************\\n    > ******************************\\n    >\\n    > *****************************\\n    > ****************************\\n    >\\n    > ***************************\\n    > **************************\\n    >\\n    > *************************\\n    > ************************\\n    > ***********************\\n    >\\n    > **********************\\n    > *********************\\n    > ********************\\n    > *******************\\n    > ******************\\n    > *****************\\n    > ****************\\n    > ***************\\n    > **************\\n    > *************\\n    > ************\\n    > ***********\\n    > **********\\n    > *********\\n    > ********\\n    > *******\\n    > ******\\n    > *****\\n    > ****\\n    > ***\\n    > **\\n    > *\\n    > **\\n    > ***\\n    > ****\\n    > *****\\n    > ******\\n    > *******\\n    > ********\\n    > *********\\n    > **********\\n    > ***********\\n    > ************\\n    > *************\\n    >\\n    > **************\\n    > ***************\\n    > ****************\\n    > *****************\\n    >\\n    > ******************\\n    > *******************\\n    > ********************\\n    > *********************\\n    > **********************\\n    > ***********************\\n    > ************************\\n    >\\n    > *************************\\n    > **************************\\n    >\\n    > ***************************\\n    > ****************************\\n    >\\n    > *****************************\\n    > ******************************\\n    >\\n    > *******************************\\n    > ********************************\\n    >\\n    > *********************************\\n    > **********************************\\n    >\\n    > ***********************************\\n    > **********************************\\n    >\\n    > *********************************\\n    > ********************************\\n    >\\n    > *******************************\\n    > ******************************\\n    >\\n    > *****************************\\n    > ****************************\\n    >\\n    > ***************************\\n    > **************************\\n    >\\n    > *************************\\n    > ************************\\n    > ***********************\\n    >\\n    > **********************\\n    > *********************\\n    > ********************\\n    > *******************\\n    > ******************\\n    > *****************\\n    > ****************\\n    > ***************\\n    > **************\\n    > *************\\n    > ************\\n    > ***********\\n    > **********\\n    > *********\\n    > ********\\n    > *******\\n    > ******\\n    > *****\\n    > ****\\n    > ***\\n    > **\\n    > *\\n    > **\\n    > ***\\n    > ****\\n    > *****\\n    > ******\\n    > *******\\n    > ********\\n    > *********\\n    > **********\\n    > ***********\\n    > ************\\n    > *************\\n    >\\n    > **************\\n    > ***************\\n    > ****************\\n    > *****************\\n    >\\n    > ******************\\n    > *******************\\n    > ********************\\n    > *********************\\n    > **********************\\n    > ***********************\\n    > ************************\\n    >\\n    > *************************\\n    > **************************\\n    >\\n    > ***************************\\n    > ****************************\\n    >\\n    > *****************************\\n    > ******************************\\n    >\\n    > *******************************\\n    > ********************************\\n    >\\n    > *********************************\\n    > **********************************\\n    >\\n    > ***********************************\\n    > **********************************\\n    >\\n    > *********************************\\n    > ********************************\\n    >\\n    > *******************************\\n    > ******************************\\n    >\\n    > *****************************\\n    > ****************************\\n    >\\n    > ***************************\\n    > **************************\\n    >\\n    > *************************\\n    > ************************\\n    > ***********************\\n    >\\n    > **********************\\n    > *********************\\n    > ********************\\n    > *******************\\n    > ******************\\n    > *****************\\n    > ****************\\n    > ***************\\n    > **************\\n    > *************\\n    > ************\\n    > ***********\\n    > **********\\n    > *********\\n    > ********\\n    > *******\\n    > ******\\n    > *****\\n    > ****\\n    > ***\\n    > **\\n    > *\\n    >\\n    >\\n    >\\n    > STOP!!!!!!!!\\n    > Congratulations!!!!!!!!!!!!!!!!!\\n    > Your wish\\n    > will  now come true in your age minutes!!\\n    > Now\\n    > follow this  carefully.... it can be very\\n    > rewarding!!!! If  you send this\\n    > to 10 more people, other\\n    > than the 5\\n    > that youalready  have to send to,\\n    > something major that you*ve been\\n    > wanting will\\n    > happpen\\n    >\\n    >\\n    >\\n    > __________________________________________________\\n    > Do You Yahoo!?\\n    > Thousands of\\n    > Stores.  Millions of Products.  All in one Place.\\n    > http://shopping.yahoo.com/ <http://shopping.yahoo.com/>\\n<<http://shopping.yahoo.com/ <http://shopping.yahoo.com/> >>\\n    >\\n\\n\\n\\n',\n",
      " u'filename': u'454.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 06:59:00 -0800 (PST)',\n",
      "              u'From': u'matthew.lenhart@enron.com',\n",
      "              u'Message-ID': u'<12292910.1075854677508.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'Sorry, I keep getting these things.',\n",
      "              u'To': u'chad.landry@enron.com, timothy.blanchard@enron.com, bryan.hull@enron.com, \\r\\n\\teric.bass@enron.com, phillip.love@enron.com, \\r\\n\\tkenneth.shulklapper@enron.com, jay.reitmeyer@enron.com, \\r\\n\\ttori.kuykendall@enron.com, lisa.gillette@enron.com, \\r\\n\\tchrista.winfrey@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Matthew Lenhart',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Chad Landry, Timothy Blanchard, Bryan Hull, Eric Bass, Phillip M Love, Kenneth Shulklapper, Jay Reitmeyer, Tori Kuykendall, Lisa Gillette, Christa Winfrey',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2e'),\n",
      " u'body': u'---------------------- Forwarded by Jackson Logan/HOU/ECT on 11/14/2000 11:22 \\nAM ---------------------------\\n\\n\\n\"Tara Talbot\" <ttalbot@bmoh.com> on 11/14/2000 11:10:57 AM\\nTo: <matthew.overbeck@ac.com>, <Peter_Bourland@adc.com>, \\n<Danielle_Deipolyi@AIMFUNDS.com>, <Meredith_O\\'Neal@AIMFUNDS.com>, \\n<Robby_White@ajg.com>, <brian.holmes@algx.com>, <JLewis1342@aol.com>, \\n<JRayb10104@aol.com>, <MJanMyersMartin@aol.com>, <Talbotjohn@aol.com>, \\n<Jeffrey.T.Harris@betzdearborn.com>, <gandrews@bmoh.com>, \\n<rsteel@border.net>, <jmcanelly@bracepatt.com>, <mat@buckfund.com>, \\n<JChapa@calpine.com>, <abedford@central.uh.edu>, <RMassey@central.uh.edu>, \\n<mfriou@citysearch.com>, <hrobert@conroe.isd.tenet.edu>, \\n<JRBridenstine@cs.com>, <ajohnston@doubleclick.net>, <gkaminski@dttus.com>, \\n<sarah.goerner@dynegy.co.uk>, <chad.starnes@enron.com>, \\n<Jackson.Logan@enron.com>, <james.hull@enron.com>, \\n<christine_petru@gensler.com>, <benleewallace@hotmail.com>, \\n<ed_cardenas@hotmail.com>, <jphilipfriday@hotmail.com>, \\n<lesleyconte@hotmail.com>, <medunkin@hotmail.com>, <sharidans@hotmail.com>, \\n<tifftalbot@hotmail.com>, <akent@khmx.com>, <jknight@knightrealestate.com>, \\n<HowardP@kochind.com>, <Ashley_Morrison@lotus.com>, <jricks@mccoyinc.com>, \\n<jameslhull@msn.com>, <lkhowell@msn.com>, <cwalker@peserve.com>, \\n<JohnWheeler@PZLQS.com>, <MikeShankleton@PZLQS.com>, \\n<sonia_m_ghaffari@reliantenergy.com>, <pkettler@reliantenergy.nl>, \\n<knust@rice.edu>, <ryaf@softchoice.com>, <lpnance@sprintparanet.com>, \\n<jmercer@timebanc.com>, <alina.r.contreras@us.arthurandersen.com>, \\n<carey.t.ford@us.arthurandersen.com>, \\n<michael.t.wardlaw@us.arthurandersen.com>, <Ronnye.E.Kettler@USA.conoco.com>, \\n<kevin.swantkowski@vignette.com>, <bpisklak@yahoo.com>, \\n<brittkaiser@yahoo.com>, <jjackson_77057@yahoo.com>, <skjones_99@yahoo.com>\\ncc:  \\nSubject: Fwd: FW: Aggies Demand a Recount\\n\\n\\n\\n>>> Ellyn Haikin 11/14/00 10:57AM >>>\\n\\nSubject: FW: Aggies Demand a Recount\\n\\nCollege Station, TX (AP) - R.C. Slocum and the Texas A&M Aggies are\\ndemanding a recount of the game in which Oklahoma won 35 to 31. \"The end \\nzones were confusing,\" says Slocum. \"I\\'m sure that some of the touchdowns \\nthat went in Oklahoma\\'s end zone were meant to go into ours.\\n\\nWe were scoring in those end zones also.  Oklahoma would never have scored \\nthirty-five points. There\\'s no way we lost this one. A&M demands a recount.\"\\n\\nOklahoma officials are calling this \"outrageous\". \"They agreed to the size, \\nshape and locations of the end zones prior to kick-off,\" replies OU coach Bob \\nStoops.  \"If they had a problem with them, they should have said so before we \\nstarted. You don\\'t get to keep playing until you\\'re happy with the outcome.  \\nSomeone had to lose.  We\\'ve scored over thirty-five points many times.\"\\n\\nA&M has sent lawyers, farmers, and those guys in the funny boots as well as \\nthat damn dog down to Kyle Field, where the scoreboard will be tested.  \"We \\nare confident that when the points are re-totaled, we will be the winner of \\nthe game,\" says Slocum.\\n\\nOU also points out that in many games prior to this one, the same end zones \\nwere used. \"They didn\\'t have a problem with the end zones until they lost,\" \\nsays Stoops.\\n\\nOutside of Kyle Field, A&M student protesters have gathered outside bearing \\nsigns such as, \"A&M wants a fair game! WHOOOOOOP!\" Students\\' thoughts echoed \\ntheir signs. \"All we want is a fair total of the points before we declare a \\nwinner,\" says student Karen Hays, an aggie from Marfa.\\n\\n\"We need to proceed cautiously and not rush to judgment before we declare a \\nwinner.\"\\n\\nABC, around 2:00pm central time, had mistakenly declared A&M the winner, \\ndespite the slim 3 point lead the Aggies held at that point. At about 2:30 \\npm, with the game still to close to call, ABC had to back off its prediction.\\n\\nCollege football analyst Brent Musburger made the call. \"We felt that with a \\nnumber of points still not added in by Jamaar Tombs and the Aggies, we were \\ncertain A&M would carry this game. We may have been premature in our \\nprediction.\"\\n\\n\\n>William G. Lowerre\\n>Schweinle, Parish & Lowerre, P.C.\\n>1001 Fannin, Suite 3800\\n>Houston TX 77002\\n>713-654-4111\\n>713-655-9485 (fax)\\n\\n\\n',\n",
      " u'filename': u'457.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 03:22:00 -0800 (PST)',\n",
      "              u'From': u'jackson.logan@enron.com',\n",
      "              u'Message-ID': u'<12170948.1075854677578.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'Fwd: FW: Aggies Demand a Recount',\n",
      "              u'To': u'phillip.love@enron.com, eric.bass@enron.com, darron.giron@enron.com, \\r\\n\\tvictor.guggenheim@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Jackson Logan',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Phillip M Love, Eric Bass, Darron C Giron, Victor Guggenheim',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n",
      "{u'_id': ObjectId('4f16fc97d1e2d32371003e2f'),\n",
      " u'body': u'The hits just keep on coming.\\n---------------------- Forwarded by Steve Venturatos/HOU/ECT on 11/14/2000 \\n11:23 AM ---------------------------\\n\\n\\n\"Bradley Rome\" <brome@br-inc.com> on 11/14/2000 11:14:31 AM\\nPlease respond to <brome@br-inc.com>\\nTo: <DSLMIL@aol.com>, <jrobertson@datarecall.net>, \\n<landquest@worldnet.att.net>, <louviereej@stone-energy.com>, \\n<marshall@millinglaw.com>, <sdbaker10@hotmail.com>, <sventur@enron.com>, \\n<wbailey@gamde.com>\\ncc:  \\nSubject: fwd: FW: Fwd: Picture worth a thousand words\\n\\n\\n\\n\\n\\nBradley J. Rome, CPL/ESA\\nSenior Staff Landman\\nBurlington Resources Oil & Gas Company\\nbrome@br-inc.com\\n---------- Original Text ----------\\n\\nFrom: \"Bailey, James W\" <bailejw@texaco.com>, on 11/14/2000 9:41 AM:\\nTo: Bradley Rome@LND@GCD\\n\\n\\n\\n-----Original Message-----\\nFrom: Bob Byars [mailto:bbyars@eplweb.com]\\nSent: Tuesday, November 14, 2000 9:14 AM\\nTo: Barry Groff (E-mail); Dave Hackney (E-mail); Doug Bowling (E-mail);\\nGeorge Grau (E-mail); Jay Martin (E-mail); Jim Bailey (E-mail); Jim\\nVance (E-mail); Kevin Ashley (E-mail); Leanne Cantrell (E-mail); Lew\\nScott (E-mail); Mike Bowman (E-mail); Steve Bohnet (E-mail); Tim Walker\\n(E-mail); Todd Burkes (E-mail)\\nSubject: FW: Fwd: Picture worth a thousand words\\n\\n\\n\\n\\n>  -----Original Message-----\\n> From:  Lisa LaHoste\\n> Sent: Tuesday, November 14, 2000 6:00 AM\\n> To: Barbara Meyer; Bob Murphy; Bob Byars\\n> Subject: Fwd: Picture worth a thousand words\\n>\\n>  <<algore.jpg>>\\n>\\n> Lisa LaHoste\\n> Energy Partners, LTD.\\n> Engineering Technician\\n> East Bay Field\\n> (504) 799 -1919\\n> (504) 799 -1910 Fax\\n> llahoste@eplweb.com\\n>\\n\\n\\n\\n\\n - algore.jpg\\n',\n",
      " u'filename': u'458.',\n",
      " u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "              u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "              u'Date': u'Tue, 14 Nov 2000 03:22:00 -0800 (PST)',\n",
      "              u'From': u'steve.venturatos@enron.com',\n",
      "              u'Message-ID': u'<9317476.1075854677600.JavaMail.evans@thyme>',\n",
      "              u'Mime-Version': u'1.0',\n",
      "              u'Subject': u'fwd: FW: Fwd: Picture worth a thousand words',\n",
      "              u'To': u'jody.crook@enron.com, david.baumbach@enron.com, kelly.lombardi@enron.com, \\r\\n\\tbryan.hull@enron.com, eric.bass@enron.com, patrick.ryder@enron.com, \\r\\n\\tdenver.plachy@enron.com, yvette.connevey@enron.com, \\r\\n\\tpat.clynes@enron.com, daren.farmer@enron.com',\n",
      "              u'X-FileName': u'ebass.nsf',\n",
      "              u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "              u'X-From': u'Steve Venturatos',\n",
      "              u'X-Origin': u'Bass-E',\n",
      "              u'X-To': u'Jody Crook, David Baumbach, Kelly Lombardi, Bryan Hull, Eric Bass, Patrick Ryder, Denver Plachy, Yvette G Connevey, Pat Clynes, Daren J Farmer',\n",
      "              u'X-bcc': u'',\n",
      "              u'X-cc': u''},\n",
      " u'mailbox': u'bass-e',\n",
      " u'subFolder': u'notes_inbox'}\n"
     ]
    }
   ],
   "source": [
    "msg = get_collection()\n",
    "d = msg.find().limit(10)\n",
    "for a in d:\n",
    "    pprint(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\n",
    "\n",
    "Write a function which returns the amount of emails in the messages collection in total. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_amount_of_messages",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_amount_of_messages(collection1):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the amount of documents in the collection\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    num = collection1.count_documents({})\n",
    "    \n",
    "    return num\n",
    "    \n",
    "get_amount_of_messages(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) \n",
    "\n",
    "Write a function which returns each person who was BCCed on an email.  Include each person only once, and display only their name according to the X-To header. [4 points] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_bcced_people",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'',\n",
      " u'Nettelton, Marcus',\n",
      " u'Apollo, Beth',\n",
      " u\"'Martin.W.Penkwitz@enron.com', Berg, Mary\",\n",
      " u'Guinn, Linda',\n",
      " u'Wood, Kim',\n",
      " u'Evans, Mark',\n",
      " u'Susan J Mara',\n",
      " u'Delahay, Julie',\n",
      " u'Cole, Kate',\n",
      " u\"'lpinder@enron.com', 'lstoler@enron.com', Watanabe, Luiz\",\n",
      " u\"'jrigby@enron.com', 'jtalcott@enron.com', Chin, Julia H.\",\n",
      " u'Guerrero, Janel',\n",
      " u\"'kathleen_magruder@enron.com', Mann, Kay\",\n",
      " u'Barry, Patrick',\n",
      " u'Boyd, Justin',\n",
      " u'Choate, Heather',\n",
      " u'Robertson, Audrey',\n",
      " u'Mellencamp, Lisa',\n",
      " u\"'mkeyser@enron.com', 'mmalmeida@elektro.com.br', 'mmanly@newpower.com', 'mmaxwel@enron.com', Maynard, Marc\",\n",
      " u\"'hfromer@enron.com', Magual, Ibrahim\",\n",
      " u'Beth Apollo',\n",
      " u\"'jhartso@enron.com', 'jhillego@enron.com', 'jhmoore@enron.com', Armogida, Jim\",\n",
      " u\"'cameron@perfect.com'\",\n",
      " u'Perry, Renee',\n",
      " u'Ogenyi, Gloria',\n",
      " u'Schwartzenburg, John',\n",
      " u'Azevedo, Karla',\n",
      " u'Wehring, Linda',\n",
      " u'Young, Kay',\n",
      " u'Pardue, Larry',\n",
      " u\"'michael.moran@enron.com', Schuh, Michael\",\n",
      " u'Robichaux, Lisa',\n",
      " u\"'jale@azurix.com', Derrick Jr., James\",\n",
      " u'hgovenar',\n",
      " u'Smalling, Michael J.',\n",
      " u'Carr, James',\n",
      " u'Novak, John',\n",
      " u'Cook, Mary',\n",
      " u'Scott Govenar',\n",
      " u'De La Paz, Janet',\n",
      " u'Leibman, Lara',\n",
      " u'Blair, Jean',\n",
      " u'Taylor, Mark',\n",
      " u'Bryan, Randy',\n",
      " u\"'Marie_Heard@enron.net', Antonvich, Mark\",\n",
      " u'Hogan, Irena D.',\n",
      " u'Sullivan, Kathleen',\n",
      " u'Holsworth, Mark',\n",
      " u\"'kristina_mordaunt@enron.net', 'ksiess@enron.com', 'kwilkie@enron.com', Schuler-Legal, Lance\",\n",
      " u\"'jkeller@enron.com', 'jmargalith@elektro.com.br', 'jmigden@enron.com', 'joe_hrabik@enronfm.com', Ephross, Joel\",\n",
      " u'Greg Piper',\n",
      " u'Patti Thompson',\n",
      " u'Viverito, John',\n",
      " u'Greenberg, Mark',\n",
      " u'Cash, Michelle',\n",
      " u'Lamb, John',\n",
      " u'Robison, Michael',\n",
      " u\"'Mack_Shively@pgn.com', Anderson, Marcia\",\n",
      " u'Beck, Sally',\n",
      " u'Twiggs, Thane',\n",
      " u'Storey, Geoff',\n",
      " u'Ratliff, Dale',\n",
      " u'Callans, Nancy',\n",
      " u'Washington, Kathy',\n",
      " u\"'david.beck@houston.rr.com'\",\n",
      " u'Lee, Matthias',\n",
      " u'Lokey, Teb',\n",
      " u'Murray, Julia',\n",
      " u\"'lgleason@enron.com', 'lhuber@enron.com', Nissan, Limor\",\n",
      " u'Johnson, Jan',\n",
      " u'Kasbekar, Lena',\n",
      " u'Haedicke, Mark',\n",
      " u'Carnahan, Kathleen',\n",
      " u'Shapiro, Richard',\n",
      " u'Harry Kingerski',\n",
      " u'Robert Superty',\n",
      " u\"'llawner@enron.com', Soldano, Louis\",\n",
      " u'Davis, Dana',\n",
      " u'Ogden, Mary',\n",
      " u'Cooley, Jan',\n",
      " u'McBride, Jane',\n",
      " u'Piper, Greg',\n",
      " u'Heinitz, Mary',\n",
      " u'Causey, Richard',\n",
      " u\"'jay_dudley@pgn.com', 'jdenicol@newpower.com', Hodge, Jeffrey\",\n",
      " u'Butler, Janet',\n",
      " u\"'mcastano@enron.com', Winn, Melinda\",\n",
      " u'Mayer, Laurie',\n",
      " u'Walden, Shirley',\n",
      " u\"'ddavissprint20@earthlink.net'\",\n",
      " u'Vuittonet, Laura',\n",
      " u'Trevino, Maricela',\n",
      " u'Porter, Diana',\n",
      " u'Jordan, Mike',\n",
      " u'Braddy, Martha',\n",
      " u'Place, Janet',\n",
      " u'Hagerty, Lauren',\n",
      " u\"'michaelrbrown@enron.com', Blaine, Michelle\",\n",
      " u'Dyson, Fernley',\n",
      " u'Oscar, Mary Denise',\n",
      " u'Powell, Mark',\n",
      " u'James D Steffes',\n",
      " u\"'john_zimmerman@eott.com', Mintz, Jordan\",\n",
      " u\"'molly_sample@eott.com', Jordan Richards, Monica\",\n",
      " u'Dernehl, Ginger',\n",
      " u'Villarreal, Alex',\n",
      " u'Steffes, James D.',\n",
      " u'Wilson, Jane',\n",
      " u'Collins, Harry',\n",
      " u'Gilbert-smith, Doug',\n",
      " u'Dawson, Matthew',\n",
      " u'Bishop, Larry',\n",
      " u'Westbrook, Cherylene R.',\n",
      " u\"'kbennic@enron.com', 'kcollins@enron.com', 'kcordova@enron.com', 'kenton_erwin@enron.net', 'khiggas@enron.com', 'kringbl@enron.com', Sullivan, Kriste\",\n",
      " u'Jones, Karen E.',\n",
      " u'Richard Shapiro',\n",
      " u'Desrochers, Jim',\n",
      " u'Clapper, Karen',\n",
      " u\"'mpavlou@enron.com'\",\n",
      " u\"'michelle_hicks@enron.net', Mendoza, Miguel\",\n",
      " u'Denny, Jennifer',\n",
      " u'Moore, Janice',\n",
      " u'Rangel, Ina',\n",
      " u\"'gmendel@azurix.com', Davis, Hardie\"]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_bcced_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the names of the people who have received an email by BCC\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    Name= []\n",
    "    #filter = {\"headers.X-bcc\":{'$exists':True}};\n",
    "    #filter = {\"headers.X-bcc\":{'$ne':''}};\n",
    "    filter = {\"$and\": [{\"headers.X-bcc\":{'$exists':True}}, {\"headers.X-bcc\":{'$ne':''}}]}\n",
    "    \n",
    "    fields = {'_id': False, 'headers.X-bcc': True}\n",
    "    name = collection.find(filter, fields)\n",
    "    #for n in name:\n",
    "    #    names = name.split(\",\")\n",
    "    #    Name.appemd(names)\n",
    "    #for i in Name:\n",
    "    #    print(i)\n",
    "    \n",
    "    \n",
    "#     for n in name:\n",
    "#         pprint(n) \n",
    "    Name_list = []        \n",
    "    for str in name:\n",
    "        #pprint(str)\n",
    "        string = str['headers']['X-bcc']\n",
    "        Name = re.split(r'<.+?>', string)\n",
    "        for Name2 in Name:\n",
    "            #print Name2\n",
    "            Name3 = Name2.strip(', ')        \n",
    "            #print(Name3)\n",
    "            Name_list.append(Name3)\n",
    "        \n",
    "    result = list(set(Name_list))\n",
    "    pprint(result)\n",
    "    \n",
    "    pass\n",
    "\n",
    "get_bcced_people(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "Write a function with parameter subject, which gets all emails in a thread with that parameter, and orders them by date (ascending). “An email thread is an email message that includes a running list of all the succeeding replies starting with the original email.”, check for detail descriptions at https://www.techopedia.com/definition/1503/email-thread [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_in_thread",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2000, 11, 14, 4, 17),\n",
       "  {u'_id': ObjectId('4f16fc98d1e2d32371004365'),\n",
       "   u'body': u\"I know I might seem a little obsessed with this, but here are some of our \\nplays from our flag football league.  There are plays on both tabs.\\nI was thinking that we would start with me at left flanker, Paul Broderick at \\ncenter, Paul Burkhart at right slot, Steve at right flanker, Sarah at \\nblocker, and either Mike or Chris at blocker.  Let me know if you have \\nobjections.  Also, I am sending this to Paul Burkhart so I am assuming that \\nhe will play (P. Broderick can you confirm this?).\\n\\nSteve - if you have some plays from your team that you think might work let \\nme know.\\n\\nLet me know what you think.\\n\\nHook 'Em!\\n-Eric\\n\\n\\n\",\n",
       "   u'filename': u'77.',\n",
       "   u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
       "    u'Content-Type': u'text/plain; charset=us-ascii',\n",
       "    u'Date': u'Tue, 14 Nov 2000 04:17:00 -0800 (PST)',\n",
       "    u'From': u'eric.bass@enron.com',\n",
       "    u'Message-ID': u'<2202976.1075854684379.JavaMail.evans@thyme>',\n",
       "    u'Mime-Version': u'1.0',\n",
       "    u'Subject': u'Plays and other information',\n",
       "    u'To': u'luis.mena@enron.com, michael.simmons@enron.com, paul.broderick@enron.com, \\r\\n\\tpaul.burkhart@enron.com, stephen.schwarzbach@enron.com, \\r\\n\\tchristopher.chenoweth@enron.com',\n",
       "    u'X-FileName': u'ebass.nsf',\n",
       "    u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Sent',\n",
       "    u'X-From': u'Eric Bass',\n",
       "    u'X-Origin': u'Bass-E',\n",
       "    u'X-To': u'Luis Mena, Michael Simmons, Paul J Broderick, Paul Burkhart, Stephen Schwarzbach, Christopher Chenoweth',\n",
       "    u'X-bcc': u'',\n",
       "    u'X-cc': u''},\n",
       "   u'mailbox': u'bass-e',\n",
       "   u'subFolder': u'sent'}),\n",
       " (datetime.datetime(2000, 11, 14, 7, 37),\n",
       "  {u'_id': ObjectId('4f16fc97d1e2d32371003e28'),\n",
       "   u'body': u'suggestion... make a playbook that just shows individual routes.. that way \\nLuis can just customize  in the huddle....\\n\\nEx.   outs, curls, out-and-up, post..  etc...     \\n\\n\\nalso,,    You give routes to the linemen and they should block  and then roll \\nout into the open flats once the defense goes past.... \\n\\nAND... most importantly.. how did you  draw those plays  excel....\\n\\n',\n",
       "   u'filename': u'451.',\n",
       "   u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
       "    u'Content-Type': u'text/plain; charset=us-ascii',\n",
       "    u'Date': u'Tue, 14 Nov 2000 07:37:00 -0800 (PST)',\n",
       "    u'From': u'michael.simmons@enron.com',\n",
       "    u'Message-ID': u'<6098626.1075854677438.JavaMail.evans@thyme>',\n",
       "    u'Mime-Version': u'1.0',\n",
       "    u'Subject': u'Re: Plays and other information',\n",
       "    u'To': u'eric.bass@enron.com',\n",
       "    u'X-FileName': u'ebass.nsf',\n",
       "    u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
       "    u'X-From': u'Michael Simmons',\n",
       "    u'X-Origin': u'Bass-E',\n",
       "    u'X-To': u'Eric Bass',\n",
       "    u'X-bcc': u'',\n",
       "    u'X-cc': u''},\n",
       "   u'mailbox': u'bass-e',\n",
       "   u'subFolder': u'notes_inbox'}),\n",
       " (datetime.datetime(2000, 11, 14, 8, 0),\n",
       "  {u'_id': ObjectId('4f16fc98d1e2d32371004344'),\n",
       "   u'body': u\"we will have a list of patterns just in case people don't know what they are, \\nbut the plays are designed to clear out areas so that certain patterns are \\nmore open.\\nyou can draw plays in excel using the drawing toolbar.\\n\\nwhat time are we going to scrimmage tomorrow?\\n\\n\\n\\n\\n\\n\\nMichael Simmons\\n11/14/2000 03:37 PM\\nTo: Eric Bass/HOU/ECT@ECT\\ncc:  \\nSubject: Re: Plays and other information  \\n\\nsuggestion... make a playbook that just shows individual routes.. that way \\nLuis can just customize  in the huddle....\\n\\nEx.   outs, curls, out-and-up, post..  etc...     \\n\\n\\nalso,,    You give routes to the linemen and they should block  and then roll \\nout into the open flats once the defense goes past.... \\n\\nAND... most importantly.. how did you  draw those plays  excel....\\n\\n\\n\\n\\n\",\n",
       "   u'filename': u'74.',\n",
       "   u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
       "    u'Content-Type': u'text/plain; charset=us-ascii',\n",
       "    u'Date': u'Tue, 14 Nov 2000 08:00:00 -0800 (PST)',\n",
       "    u'From': u'eric.bass@enron.com',\n",
       "    u'Message-ID': u'<10938098.1075854684315.JavaMail.evans@thyme>',\n",
       "    u'Mime-Version': u'1.0',\n",
       "    u'Subject': u'Re: Plays and other information',\n",
       "    u'To': u'michael.simmons@enron.com',\n",
       "    u'X-FileName': u'ebass.nsf',\n",
       "    u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Sent',\n",
       "    u'X-From': u'Eric Bass',\n",
       "    u'X-Origin': u'Bass-E',\n",
       "    u'X-To': u'Michael Simmons',\n",
       "    u'X-bcc': u'',\n",
       "    u'X-cc': u''},\n",
       "   u'mailbox': u'bass-e',\n",
       "   u'subFolder': u'sent'}),\n",
       " (datetime.datetime(2000, 11, 14, 8, 22),\n",
       "  {u'_id': ObjectId('4f16fc97d1e2d32371003e27'),\n",
       "   u'body': u\"the scrimmage is still up in the air...\\n\\n\\nwebb said that they didnt want to scrimmage...\\n\\nthe aggies  are scrimmaging each other... (the aggie teams practiced on \\nSunday)\\n\\nwhen I called the aggie captains to see if we could use their field.... they \\nsaid that it was tooo smalll for us to use...\\n\\n\\nsounds like bullshit to me... but what can we do....\\n\\n\\nanyway... we will have to do another practice Wed. night....    and I dont' \\nknow where we can practice.... any suggestions...\\n\\n\\nalso,  we still need one  more person...\",\n",
       "   u'filename': u'450.',\n",
       "   u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
       "    u'Content-Type': u'text/plain; charset=us-ascii',\n",
       "    u'Date': u'Tue, 14 Nov 2000 08:22:00 -0800 (PST)',\n",
       "    u'From': u'michael.simmons@enron.com',\n",
       "    u'Message-ID': u'<6884142.1075854677416.JavaMail.evans@thyme>',\n",
       "    u'Mime-Version': u'1.0',\n",
       "    u'Subject': u'Re: Plays and other information',\n",
       "    u'To': u'eric.bass@enron.com',\n",
       "    u'X-FileName': u'ebass.nsf',\n",
       "    u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
       "    u'X-From': u'Michael Simmons',\n",
       "    u'X-Origin': u'Bass-E',\n",
       "    u'X-To': u'Eric Bass',\n",
       "    u'X-bcc': u'',\n",
       "    u'X-cc': u''},\n",
       "   u'mailbox': u'bass-e',\n",
       "   u'subFolder': u'notes_inbox'}),\n",
       " (datetime.datetime(2000, 11, 14, 23, 42),\n",
       "  {u'_id': ObjectId('4f16fc98d1e2d32371004339'),\n",
       "   u'body': u\"Hey Paul,\\n\\nI left a msg in your voice mail, but the low down is that the ENE/AC Flag \\nFootball tourney is Saturday and we would like you to play.  The tourney \\nstarts at 10 and is 3 hours long.  If we win, we get 16 tickets to the game \\n(2 for each of us).  Let me know if you are interested.\\n\\nThanks,\\n\\nEric\\nx3-0977\\n\\n\\nFrom: Paul Burkhart@ENRON COMMUNICATIONS on 11/14/2000 05:51 PM\\nTo: Eric Bass/HOU/ECT@ECT@ENRON\\ncc:  \\nSubject: Re: Plays and other information  \\n\\nHope all is well.  Is this in reference to the Enron/Andersen Consulting \\nfootball game?  When is it?  Do you need me to play?  Give me a call and we \\ncan discuss (3-9557).  \\n\\nThanks,\\n\\nPaul\\n\\n\\n\\n\\n\\n\\tEric Bass@ECT\\n\\t11/14/00 12:17 PM\\n\\t\\t \\n\\t\\t To: Luis Mena/NA/Enron@Enron, Michael Simmons/HOU/ECT@ECT, Paul J \\nBroderick/HOU/ECT@ECT, Paul Burkhart/Enron Communications@Enron \\nCommunications, Stephen Schwarzbach/Corp/Enron@Enron, Christopher \\nChenoweth/NA/Enron@Enron\\n\\t\\t cc: \\n\\t\\t Subject: Plays and other information\\n\\nI know I might seem a little obsessed with this, but here are some of our \\nplays from our flag football league.  There are plays on both tabs.\\nI was thinking that we would start with me at left flanker, Paul Broderick at \\ncenter, Paul Burkhart at right slot, Steve at right flanker, Sarah at \\nblocker, and either Mike or Chris at blocker.  Let me know if you have \\nobjections.  Also, I am sending this to Paul Burkhart so I am assuming that \\nhe will play (P. Broderick can you confirm this?).\\n\\nSteve - if you have some plays from your team that you think might work let \\nme know.\\n\\nLet me know what you think.\\n\\nHook 'Em!\\n-Eric\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
       "   u'filename': u'73.',\n",
       "   u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
       "    u'Content-Type': u'text/plain; charset=us-ascii',\n",
       "    u'Date': u'Tue, 14 Nov 2000 23:42:00 -0800 (PST)',\n",
       "    u'From': u'eric.bass@enron.com',\n",
       "    u'Message-ID': u'<26401781.1075854684294.JavaMail.evans@thyme>',\n",
       "    u'Mime-Version': u'1.0',\n",
       "    u'Subject': u'Re: Plays and other information',\n",
       "    u'To': u'paul.burkhart@enron.com',\n",
       "    u'X-FileName': u'ebass.nsf',\n",
       "    u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Sent',\n",
       "    u'X-From': u'Eric Bass',\n",
       "    u'X-Origin': u'Bass-E',\n",
       "    u'X-To': u'Paul Burkhart',\n",
       "    u'X-bcc': u'',\n",
       "    u'X-cc': u''},\n",
       "   u'mailbox': u'bass-e',\n",
       "   u'subFolder': u'sent'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = 'Plays and '\n",
    "def get_emails_in_thread(collection, subject):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails in the thread with that subject\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE   \n",
    "    match = {\n",
    "        \"$match\": {\"headers.Subject\": {\"$regex\": subject}}\n",
    "    }\n",
    "    cursor = collection.aggregate([match])\n",
    "#     pprint (list(cursor))\n",
    "    date1 = {}\n",
    "    for date in cursor:\n",
    "        Datetime = datetime.strptime(date['headers']['Date'][5:-12], \"%d %b %Y %H:%M:%S\")\n",
    "        date1.update({Datetime: date})\n",
    "        \n",
    "#     pprint(date1)\n",
    "#     pprint (sorted(date1, reverse=True))\n",
    "    return sorted(date1.items(), key=lambda k: k[0])\n",
    "    \n",
    "get_emails_in_thread(msg, sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "\n",
    "Write a function which returns the percentage of emails sent on a weekend (i.e., Saturday and Sunday) as a `float` between 0 and 1. [6 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_percentage_sent_on_weekend",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comp6235/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0393"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentage_sent_on_weekend(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return A float between 0 and 1\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    filter = {\"$or\":[{\"headers.Date\": {\"$regex\": '^Sat'}},{\"headers.Date\": {\"$regex\": '^Sun'}}]}    \n",
    "    filter2 = collection.find(filter)\n",
    "    #for weekend in msg.find(filter):\n",
    "    #    pprint(weekend)\n",
    "    #num = filter2.count_documents()\n",
    "    num = filter2.count()\n",
    "    per = float(num)/get_amount_of_messages(collection)\n",
    "    return per\n",
    "get_percentage_sent_on_weekend(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)\n",
    "\n",
    "Write a function with parameter limit. The function should return for each email account: the number of emails sent, the number of emails received, and the total number of emails (sent and received). Use the following format: [{\"contact\": \"michael.simmons@enron.com\", \"from\": 42, \"to\": 92, \"total\": 134}] and the information contained in the To, From, and Cc headers. Sort the output in descending order by the total number of emails. Use the parameter limit to specify the number of results to be returned. If limit is null, the function should return all results. If limit is higher than null, the function should return the number of results specified as limit. limit cannot take negative values. [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_between_contacts",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('contact', u'jeff.dasovich@enron.com'), ('from', 9424), ('to', 12136), ('total', 21560)])\n",
      "OrderedDict([('contact', u'sally.beck@enron.com'), ('from', 4244), ('to', 6905), ('total', 11149)])\n",
      "OrderedDict([('contact', u'daren.farmer@enron.com'), ('from', 2812), ('to', 6275), ('total', 9087)])\n",
      "OrderedDict([('contact', u'susan.mara@enron.com'), ('from', 819), ('to', 5127), ('total', 5946)])\n",
      "OrderedDict([('contact', u'james.steffes@enron.com'), ('from', 473), ('to', 4802), ('total', 5275)])\n",
      "OrderedDict([('contact', u'richard.shapiro@enron.com'), ('from', 202), ('to', 4672), ('total', 4874)])\n",
      "OrderedDict([('contact', u'paul.kaufman@enron.com'), ('from', 197), ('to', 4501), ('total', 4698)])\n",
      "OrderedDict([('contact', u'david.delainey@enron.com'), ('from', 2959), ('to', 758), ('total', 3717)])\n",
      "OrderedDict([('contact', u'larry.campbell@enron.com'), ('from', 1380), ('to', 1894), ('total', 3274)])\n",
      "OrderedDict([('contact', u'harry.kingerski@enron.com'), ('from', 106), ('to', 3074), ('total', 3180)])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "def get_emails_between_contacts(collection, limit):\n",
    "    \"\"\"\n",
    "    Shows the communications between contacts\n",
    "    Sort by the descending order of total emails using the To, From, and Cc headers.\n",
    "    :param `collection` A PyMongo collection object    \n",
    "    :param `limit` An integer specifying the amount to display, or\n",
    "    if null will display all outputs\n",
    "    :return A list of objects of the form:\n",
    "    [{\n",
    "        'contact': <<Another email address>>\n",
    "        'from': \n",
    "        'to': \n",
    "        'total': \n",
    "    },{.....}]\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    filter_From = {\n",
    "    '$match': {\"$and\": [{\"headers.From\":{'$exists':True}}, {\"headers.From\":{'$ne':''}}]}\n",
    "    }\n",
    "    filter_Cc = {\n",
    "    '$match': {\"$and\": [{\"headers.Cc\":{'$exists':True}}, {\"headers.Cc\":{'$ne':''}}]}\n",
    "    }\n",
    "    filter_To = {\n",
    "    '$match': {\"$and\": [{\"headers.To\":{'$exists':True}}, {\"headers.To\":{'$ne':''}}]}\n",
    "    }\n",
    "    \n",
    "    Total = defaultdict(lambda: 0)\n",
    "    From_cal = defaultdict(lambda: 0)\n",
    "    To_cal = defaultdict(lambda: 0)\n",
    "    Cc_cal = defaultdict(lambda: 0)\n",
    "    \n",
    "    group1 = {\n",
    "    '$group': {\n",
    "        '_id': '$headers.From', \n",
    "        'size': {'$sum': 1},\n",
    "        }\n",
    "    }\n",
    "    limits = {\n",
    "        '$limit': 10\n",
    "    }\n",
    "    FromEmails = list(collection.aggregate([filter_From, group1]))\n",
    "#     pprint(FromEmails)\n",
    "    \n",
    "    \n",
    "    for Spl_FromEmails in FromEmails:\n",
    "        Spl_FromEmails2 = Spl_FromEmails['_id'].split(\",\")\n",
    "        for Spl_FromEmails3 in Spl_FromEmails2:\n",
    "            Spl_FromEmails4 = Spl_FromEmails3.strip()\n",
    "            From_cal[Spl_FromEmails4] = From_cal[Spl_FromEmails4] + Spl_FromEmails['size']\n",
    "            Total[Spl_FromEmails4] = Total[Spl_FromEmails4] + Spl_FromEmails['size']\n",
    "    \n",
    "    \n",
    "    group2 = {\n",
    "    '$group': {\n",
    "        '_id': '$headers.To', \n",
    "        'size': {'$sum': 1},\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    ToEmails = list(collection.aggregate([filter_To, group2]))\n",
    "#     pprint(ToEmails)\n",
    "   \n",
    "    \n",
    "    for Spl_ToEmails in ToEmails:\n",
    "        Spl_ToEmails2 = Spl_ToEmails['_id'].split(\",\")\n",
    "        for Spl_ToEmails3 in Spl_ToEmails2:\n",
    "            Spl_ToEmails4 = Spl_ToEmails3.strip()\n",
    "            To_cal[Spl_ToEmails4] = To_cal[Spl_ToEmails4] + Spl_ToEmails['size']\n",
    "            Total[Spl_ToEmails4] = Total[Spl_ToEmails4] + Spl_ToEmails['size']\n",
    "#     To_cal = sorted(To_cal.items(), key=lambda k: k[1], reverse=True)    \n",
    "    \n",
    "    group3 = {\n",
    "    '$group': {\n",
    "        '_id': '$headers.Cc', \n",
    "        'size': {'$sum': 1},\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    CcEmails = list(collection.aggregate([filter_Cc, group3]))    \n",
    "    \n",
    "\n",
    "#     pprint(CcEmails)\n",
    "    \n",
    "    for Spl_CcEmails in CcEmails:\n",
    "        Spl_CcEmails2 = Spl_CcEmails['_id'].split(\",\")\n",
    "        for Spl_CcEmails3 in Spl_CcEmails2:\n",
    "            Spl_CcEmails4 = Spl_CcEmails3.strip()\n",
    "            Cc_cal[Spl_CcEmails4] = Cc_cal[Spl_CcEmails4] + Spl_CcEmails['size']\n",
    "            Total[Spl_CcEmails4] = Total[Spl_CcEmails4] + Spl_CcEmails['size']\n",
    "#             print (Spl_CcEmails4, Spl_CcEmails['size'])\n",
    "\n",
    "#     Cc_cal = sorted(Cc_cal.items(), key=lambda k: k[1], reverse=True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    i = 1\n",
    "#     pprint(sorted(Total.items(), key=lambda k: k[1], reverse=True))\n",
    "    result = sorted(Total.items(), key=lambda k: k[1], reverse=True)\n",
    "    for count in result:\n",
    "        name = count[0]\n",
    "        From_count = From_cal[name]\n",
    "        To_count = To_cal[name]\n",
    "        Cc_count = Cc_cal[name]\n",
    "        if i > limit:\n",
    "            break\n",
    "#         print count\n",
    "        i = i+1\n",
    "        dict = {'contact':name, 'from':From_count, 'to':To_count,'total':count[1]}\n",
    "#         print (dict)  #it can work but the sequence will be total, to contact from, so I change to OrderedDict\n",
    "        od = OrderedDict()\n",
    "        od['contact'] = name\n",
    "        od['from'] = From_count\n",
    "        od['to'] = To_count + Cc_count\n",
    "        od['total'] = count[1]\n",
    "        print od\n",
    "\n",
    "#     pprint(sorted(Cc_cal.items(), key=lambda k: k[1], reverse=True))\n",
    "    \n",
    "    \n",
    "        \n",
    "#     for n in Total:\n",
    "#         print (n)\n",
    "        \n",
    "        \n",
    "    pass\n",
    "get_emails_between_contacts(msg,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)\n",
    "Write a function to find out the number of senders who were also direct receivers. Direct receiver means the email is sent to the person directly, not via cc or bcc. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411\n"
     ]
    }
   ],
   "source": [
    "def get_from_to_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the NUMBER of the people who have sent emails and received emails as direct receivers.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    send = collection.distinct(\"headers.From\")\n",
    "    receive = collection.distinct(\"headers.To\")\n",
    "    list_receive = []\n",
    "    for sp in receive:\n",
    "        sp2 = sp.split(\",\")\n",
    "        for sp3 in sp2:\n",
    "            sp4 = sp3.strip()\n",
    "#             sp5 = sp4.strip(\",\\rn\")\n",
    "            \n",
    "            #print sp5\n",
    "            list_receive.append(sp4)\n",
    "            \n",
    "    result = len(list(set(send).intersection(list_receive)))\n",
    "    return result\n",
    "\n",
    "c = get_from_to_people(msg)\n",
    "#print list(s)[:10]\n",
    "print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)\n",
    "Write a function with parameters start_date and end_date, which returns the number of email messages that have been sent between those specified dates, including start_date and end_date [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_emails_between_dates(collection, start_date, end_date):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails between the specified start_date and end_date\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    group = {\n",
    "    '$group': {\n",
    "        '_id': \"$headers.Date\", \n",
    "        'size': {'$sum': 1},        \n",
    "        }\n",
    "    }\n",
    "    limit = {\n",
    "        '$limit': 50\n",
    "    }\n",
    "    Date = list(collection.aggregate([group]))\n",
    "#     print (Date)\n",
    "    num = 0\n",
    "    for c in Date:\n",
    "        if len(c['_id']) == 36 or len(c['_id']) == 37:\n",
    "            d = datetime.strptime(c['_id'][5:-12], \"%d %b %Y %H:%M:%S\")\n",
    "            if start < d and d < end:\n",
    "#                 print d, c['size']   #This can show all of the results\n",
    "                num = num + c['size']\n",
    "    \n",
    "    return num\n",
    "\n",
    "start = datetime(2000,12,1,23,59)\n",
    "end = datetime(2000,12,2,23,59)\n",
    "get_emails_between_dates(msg, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "This task will assess your ability to use the Hadoop Streaming API and MapReduce to process data. For each of the questions below, you are expected to write two python scripts, one for the Map phase and one for the Reduce phase. You are also expected to provide the correct parameters to the `hadoop` command to run the MapReduce process. Write down your answers in the specified cells below.\n",
    "\n",
    "To get started, you need to download and unzip the YouTube dataset (available at http://edshare.soton.ac.uk/19547/) onto the machine where you have Hadoop installed (this should be the virtual machine provided).\n",
    "\n",
    "To help you, `%%writefile` has been added to the top of the cells, automatically writing them to \"mapper.py\" and \"reducer.py\" respectively when the cells are run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) \n",
    "Using Youtube01-Psy.csv, find the hourly interval in which most spam was sent. The output should be in the form of a single key-value pair, where the value is a datetime at the start of the hour with the highest number of spam comments. [9 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  YouTube-Spam-Collection-v1.zip\n",
      "-rwxrwxrwx 1 comp6235 root 57K Mar 26  2017 Youtube01-Psy.csv\n",
      "-rwxrwxrwx 1 comp6235 root 63K Mar 26  2017 Youtube02-KatyPerry.csv\n",
      "-rwxrwxrwx 1 comp6235 root 63K Mar 26  2017 Youtube03-LMFAO.csv\n",
      "-rwxrwxrwx 1 comp6235 root 81K Mar 26  2017 Youtube04-Eminem.csv\n",
      "-rwxrwxrwx 1 comp6235 root 72K Mar 26  2017 Youtube05-Shakira.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-12-12 16:38:34--  https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘archive.ics.uci.edu’\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "note:  YouTube-Spam-Collection-v1.zip may be a plain executable, not an archive\n",
      "unzip:  cannot find zipfile directory in one of YouTube-Spam-Collection-v1.zip or\n",
      "        YouTube-Spam-Collection-v1.zip.zip, and cannot find YouTube-Spam-Collection-v1.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip \\\n",
    "-O YouTube-Spam-Collection-v1.zip\n",
    "\n",
    "unzip -o YouTube-Spam-Collection-v1.zip\n",
    "\n",
    "ls -lh *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper.py\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "lines = sys.stdin.readlines()\n",
    "\n",
    "csvreader = csv.reader(lines)\n",
    "# YOUR CODE GOES BELOW\n",
    "\n",
    "# Create a list of ONLY the comments using a list comprehension\n",
    "datetime = [row[2] for row in csvreader]\n",
    "\n",
    "# Iterate over each of the comments\n",
    "for datetimes in datetime:\n",
    "    # Split the comment string into words, using every whitespace character as a divider. \n",
    "    tokens = datetimes.split(\":\", 1)[0]\n",
    "    #tokens = re.split(\"T\", datetimes)\n",
    "    #tokens = re.sub(r\"T\", ' ', datetimes)\n",
    "        #Print the key, value pair <token, 1>\n",
    "    print(tokens + \"\\t1\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer.py\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "# Keep simple example in for now, switch to stdin later\n",
    "\n",
    "input_pairs = [\n",
    "    '+447935454150\t1',\n",
    "    'lovely\t1',\n",
    "    'lovely\t1',\n",
    "    'girl\t1',\n",
    "    'talk\t1',\n",
    "    'to\t1',\n",
    "    'me\t1'\n",
    "    #'xxx\t1',\n",
    "     #Add an extra one to test that it works\n",
    "    #'to\\t1'\n",
    "]\n",
    "# Once we test this with streams, we can uncomment this next line\n",
    "input_pairs = sys.stdin.readlines()\n",
    "\n",
    "# YOUR CODE GOES BELOW\n",
    "\n",
    "# Create a default dictionary. \n",
    "# This is a key-value store (dictionary) which returns a default value if the key hasn't been added.\n",
    "# Here, we use it to store <word, count> pairs.\n",
    "accumulator = defaultdict(lambda: 0)\n",
    "\n",
    "for row in input_pairs:\n",
    "    # Split the line into our key value pair.\n",
    "    key_value_pair = row.split(\"\\t\", 1)\n",
    "    \n",
    "    # If we don't have a pair, ignore the line, as something has gone wrong.\n",
    "    if len(key_value_pair) != 2:\n",
    "        continue\n",
    "        \n",
    "    word = key_value_pair[0]\n",
    "    # Strip removes whitespace at the start and end of a string. In this case, making sure we have just a number.\n",
    "    # We also convert it to an integer here.\n",
    "    count = int(key_value_pair[1].strip())\n",
    "    \n",
    "    # Retrieve the count of that word we've seen so far, add to it, then store the result.\n",
    "    accumulator[word] = accumulator[word] + count\n",
    "    \n",
    "# for (key, value) in accumulator.items():\n",
    "#     print(key + \"\\t\" + str(value))\n",
    "\n",
    "Most_Spam = max(accumulator.iteritems(), key = lambda k: k[1])\n",
    "print(\"hour_with_most_spam\\t\\\"%s\\\"\" %(Most_Spam[0]+\":00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_with_most_spam\t\"2014-11-08T10:00:00\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod a+x mapper.py reducer.py\n",
    "cat Youtube01-Psy.csv | ./mapper.py | ./reducer.py | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop switched to standalone mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/12 16:39:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "19/12/12 16:39:09 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/12/12 16:39:09 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/12/12 16:39:09 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "19/12/12 16:39:10 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "19/12/12 16:39:10 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "19/12/12 16:39:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1380498940_0001\n",
      "19/12/12 16:39:10 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/mapper.py as file:/tmp/hadoop-comp6235/mapred/local/1576168750423/mapper.py\n",
      "19/12/12 16:39:10 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/reducer.py as file:/tmp/hadoop-comp6235/mapred/local/1576168750424/reducer.py\n",
      "19/12/12 16:39:10 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "19/12/12 16:39:10 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "19/12/12 16:39:10 INFO mapreduce.Job: Running job: job_local1380498940_0001\n",
      "19/12/12 16:39:10 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "19/12/12 16:39:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 16:39:10 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 16:39:10 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "19/12/12 16:39:10 INFO mapred.LocalJobRunner: Starting task: attempt_local1380498940_0001_m_000000_0\n",
      "19/12/12 16:39:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 16:39:10 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 16:39:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 16:39:10 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube01-Psy.csv:0+57438\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py]\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: Records R/W=351/1\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: \n",
      "19/12/12 16:39:11 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: Spilling map output\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: bufstart = 0; bufend = 5607; bufvoid = 104857600\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212996(104851984); length = 1401/6553600\n",
      "19/12/12 16:39:11 INFO mapred.MapTask: Finished spill 0\n",
      "19/12/12 16:39:11 INFO mapred.Task: Task:attempt_local1380498940_0001_m_000000_0 is done. And is in the process of committing\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Records R/W=351/1\n",
      "19/12/12 16:39:11 INFO mapred.Task: Task 'attempt_local1380498940_0001_m_000000_0' done.\n",
      "19/12/12 16:39:11 INFO mapred.Task: Final Counters for attempt_local1380498940_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=193605\n",
      "\t\tFILE: Number of bytes written=525907\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=351\n",
      "\t\tMap output bytes=5607\n",
      "\t\tMap output materialized bytes=6315\n",
      "\t\tInput split bytes=99\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=351\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=199491584\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local1380498940_0001_m_000000_0\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Starting task: attempt_local1380498940_0001_r_000000_0\n",
      "19/12/12 16:39:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 16:39:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 16:39:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 16:39:11 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1946d1f\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334154944, maxSingleShuffleLimit=83538736, mergeThreshold=220542272, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "19/12/12 16:39:11 INFO reduce.EventFetcher: attempt_local1380498940_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "19/12/12 16:39:11 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1380498940_0001_m_000000_0 decomp: 6311 len: 6315 to MEMORY\n",
      "19/12/12 16:39:11 INFO reduce.InMemoryMapOutput: Read 6311 bytes from map-output for attempt_local1380498940_0001_m_000000_0\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6311, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6311\n",
      "19/12/12 16:39:11 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "19/12/12 16:39:11 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/12/12 16:39:11 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6295 bytes\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: Merged 1 segments, 6311 bytes to disk to satisfy reduce memory limit\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: Merging 1 files, 6315 bytes from disk\n",
      "19/12/12 16:39:11 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "19/12/12 16:39:11 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/12/12 16:39:11 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6295 bytes\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././reducer.py]\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "19/12/12 16:39:11 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: Records R/W=351/1\n",
      "19/12/12 16:39:11 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 16:39:11 INFO mapred.Task: Task:attempt_local1380498940_0001_r_000000_0 is done. And is in the process of committing\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/12/12 16:39:11 INFO mapred.Task: Task attempt_local1380498940_0001_r_000000_0 is allowed to commit now\n",
      "19/12/12 16:39:11 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1380498940_0001_r_000000_0' to file:/home/comp6235/Notebooks/output/_temporary/0/task_local1380498940_0001_r_000000\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Records R/W=351/1 > reduce\n",
      "19/12/12 16:39:11 INFO mapred.Task: Task 'attempt_local1380498940_0001_r_000000_0' done.\n",
      "19/12/12 16:39:11 INFO mapred.Task: Final Counters for attempt_local1380498940_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=206267\n",
      "\t\tFILE: Number of bytes written=532276\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=182\n",
      "\t\tReduce shuffle bytes=6315\n",
      "\t\tReduce input records=351\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=351\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=199491584\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=54\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local1380498940_0001_r_000000_0\n",
      "19/12/12 16:39:11 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "19/12/12 16:39:11 INFO mapreduce.Job: Job job_local1380498940_0001 running in uber mode : false\n",
      "19/12/12 16:39:11 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/12/12 16:39:11 INFO mapreduce.Job: Job job_local1380498940_0001 completed successfully\n",
      "19/12/12 16:39:11 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=399872\n",
      "\t\tFILE: Number of bytes written=1058183\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=351\n",
      "\t\tMap output bytes=5607\n",
      "\t\tMap output materialized bytes=6315\n",
      "\t\tInput split bytes=99\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=182\n",
      "\t\tReduce shuffle bytes=6315\n",
      "\t\tReduce input records=351\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=702\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=398983168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=54\n",
      "19/12/12 16:39:11 INFO streaming.StreamJob: Output directory: output\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf output\n",
    "\n",
    "hadoop-standalone-mode.sh\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper.py,reducer.py \\\n",
    "-input Youtube01-Psy.csv \\\n",
    "-mapper ./mapper.py \\\n",
    "-reducer ./reducer.py \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#hour_with_most_spam\t\"2013-11-10T10:00:00\"\n",
    "\n",
    "#Additional key-value pairs are acceptable, as long as the hour_with_most_spam pair is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) \n",
    "Find all comments associated with a username (the AUTHOR field). Return a JSON array of all comments associated with that username. (This should use the data from all 5 data files: Psy, KatyPerry, LMFAO, Eminem, Shakira) [11 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper.py\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "lines = sys.stdin.readlines()\n",
    "\n",
    "csvreader = csv.reader(lines)\n",
    "# YOUR CODE GOES BELOW\n",
    "username1 = ' '.join(sys.argv[1:])\n",
    "\n",
    "# Create a list of ONLY the comments using a list comprehension\n",
    "\n",
    "for row in csvreader:\n",
    "    if row[1] == username1:\n",
    "        print(row[1]+\"\\t\"+row[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer.py\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "# Keep simple example in for now, switch to stdin later\n",
    "\n",
    "input_pairs = sys.stdin.readlines()\n",
    "accumulator = defaultdict(list)\n",
    "\n",
    "for row in input_pairs:\n",
    "    # Split the line into our key value pair.\n",
    "    key_value_pair = row.split(\"\\t\", 1)\n",
    "    \n",
    "    if len(key_value_pair) != 2:\n",
    "        continue\n",
    "        \n",
    "    name = key_value_pair[0]\n",
    "    # Strip removes whitespace at the start and end of a string. In this case, making sure we have just a number.\n",
    "    # We also convert it to an integer here.\n",
    "    comment = key_value_pair[1]\n",
    "    \n",
    "    # Retrieve the count of that word we've seen so far, add to it, then store the result.\n",
    "    accumulator[name].append(comment)\n",
    "    \n",
    "for (key, value) in accumulator.items():\n",
    "    print(key + \"\\t\" + str(value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_with_most_spam\t\"2014-11-08T10:00:00\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod a+x mapper.py reducer.py\n",
    "cat Youtube01-Psy.csv | ./mapper.py | ./reducer.py | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop switched to standalone mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/12 15:25:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "19/12/12 15:25:59 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/12/12 15:25:59 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/12/12 15:25:59 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "19/12/12 15:25:59 INFO mapred.FileInputFormat: Total input files to process : 5\n",
      "19/12/12 15:25:59 INFO mapreduce.JobSubmitter: number of splits:5\n",
      "19/12/12 15:25:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local515344090_0001\n",
      "19/12/12 15:26:00 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/mapper.py as file:/tmp/hadoop-comp6235/mapred/local/1576164360113/mapper.py\n",
      "19/12/12 15:26:00 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/reducer.py as file:/tmp/hadoop-comp6235/mapred/local/1576164360114/reducer.py\n",
      "19/12/12 15:26:00 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "19/12/12 15:26:00 INFO mapreduce.Job: Running job: job_local515344090_0001\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_m_000000_0\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube04-Eminem.csv:0+82896\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py, Alex, Martin]\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "19/12/12 15:26:00 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: \n",
      "19/12/12 15:26:00 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 15:26:00 INFO mapred.Task: Task:attempt_local515344090_0001_m_000000_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: file:/home/comp6235/Notebooks/Youtube04-Eminem.csv:0+82896\n",
      "19/12/12 15:26:00 INFO mapred.Task: Task 'attempt_local515344090_0001_m_000000_0' done.\n",
      "19/12/12 15:26:00 INFO mapred.Task: Final Counters for attempt_local515344090_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=218574\n",
      "\t\tFILE: Number of bytes written=517719\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=454\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=199491584\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=82896\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_m_000000_0\n",
      "19/12/12 15:26:00 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_m_000001_0\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube05-Shakira.csv:0+72706\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 15:26:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 15:26:00 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py, Alex, Martin]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: \n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task:attempt_local515344090_0001_m_000001_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: file:/home/comp6235/Notebooks/Youtube05-Shakira.csv:0+72706\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task 'attempt_local515344090_0001_m_000001_0' done.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Final Counters for attempt_local515344090_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=291813\n",
      "\t\tFILE: Number of bytes written=517757\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=371\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=304611328\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=72706\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_m_000001_0\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_m_000002_0\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube03-LMFAO.csv:0+64419\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py, Alex, Martin]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: Records R/W=439/1\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: \n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Spilling map output\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: bufstart = 0; bufend = 53; bufvoid = 104857600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Finished spill 0\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task:attempt_local515344090_0001_m_000002_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Records R/W=439/1\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task 'attempt_local515344090_0001_m_000002_0' done.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Final Counters for attempt_local515344090_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=356765\n",
      "\t\tFILE: Number of bytes written=517850\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=439\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=53\n",
      "\t\tMap output materialized bytes=61\n",
      "\t\tInput split bytes=101\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=409731072\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=64419\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_m_000002_0\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_m_000003_0\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube02-KatyPerry.csv:0+64279\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py, Alex, Martin]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: \n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task:attempt_local515344090_0001_m_000003_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: file:/home/comp6235/Notebooks/Youtube02-KatyPerry.csv:0+64279\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task 'attempt_local515344090_0001_m_000003_0' done.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Final Counters for attempt_local515344090_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=421577\n",
      "\t\tFILE: Number of bytes written=517888\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=105\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=497549312\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=64279\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_m_000003_0\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_m_000004_0\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/Youtube01-Psy.csv:0+57438\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././mapper.py, Alex, Martin]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: \n",
      "19/12/12 15:26:01 INFO mapred.MapTask: Starting flush of map output\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task:attempt_local515344090_0001_m_000004_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: file:/home/comp6235/Notebooks/Youtube01-Psy.csv:0+57438\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task 'attempt_local515344090_0001_m_000004_0' done.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Final Counters for attempt_local515344090_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=479548\n",
      "\t\tFILE: Number of bytes written=517926\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=99\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=12\n",
      "\t\tTotal committed heap usage (bytes)=497549312\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_m_000004_0\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Starting task: attempt_local515344090_0001_r_000000_0\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/12/12 15:26:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/12/12 15:26:01 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a4ff6b\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=348284512, maxSingleShuffleLimit=87071128, mergeThreshold=229867792, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "19/12/12 15:26:01 INFO reduce.EventFetcher: attempt_local515344090_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "19/12/12 15:26:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local515344090_0001_m_000003_0 decomp: 2 len: 6 to MEMORY\n",
      "19/12/12 15:26:01 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local515344090_0001_m_000003_0\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2\n",
      "19/12/12 15:26:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local515344090_0001_m_000000_0 decomp: 2 len: 6 to MEMORY\n",
      "19/12/12 15:26:01 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local515344090_0001_m_000000_0\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4\n",
      "19/12/12 15:26:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local515344090_0001_m_000004_0 decomp: 2 len: 6 to MEMORY\n",
      "19/12/12 15:26:01 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local515344090_0001_m_000004_0\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6\n",
      "19/12/12 15:26:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local515344090_0001_m_000001_0 decomp: 2 len: 6 to MEMORY\n",
      "19/12/12 15:26:01 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local515344090_0001_m_000001_0\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8\n",
      "19/12/12 15:26:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local515344090_0001_m_000002_0 decomp: 57 len: 61 to MEMORY\n",
      "19/12/12 15:26:01 INFO reduce.InMemoryMapOutput: Read 57 bytes from map-output for attempt_local515344090_0001_m_000002_0\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 57, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->65\n",
      "19/12/12 15:26:01 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs\n",
      "19/12/12 15:26:01 INFO mapred.Merger: Merging 5 sorted segments\n",
      "19/12/12 15:26:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: Merged 5 segments, 65 bytes to disk to satisfy reduce memory limit\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: Merging 1 files, 61 bytes from disk\n",
      "19/12/12 15:26:01 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "19/12/12 15:26:01 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/12/12 15:26:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/././reducer.py]\n",
      "19/12/12 15:26:01 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "19/12/12 15:26:01 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "19/12/12 15:26:01 INFO mapreduce.Job: Job job_local515344090_0001 running in uber mode : false\n",
      "19/12/12 15:26:01 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: Records R/W=1/1\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/12/12 15:26:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task:attempt_local515344090_0001_r_000000_0 is done. And is in the process of committing\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task attempt_local515344090_0001_r_000000_0 is allowed to commit now\n",
      "19/12/12 15:26:01 INFO output.FileOutputCommitter: Saved output of task 'attempt_local515344090_0001_r_000000_0' to file:/home/comp6235/Notebooks/output/_temporary/0/task_local515344090_0001_r_000000\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Records R/W=1/1 > reduce\n",
      "19/12/12 15:26:01 INFO mapred.Task: Task 'attempt_local515344090_0001_r_000000_0' done.\n",
      "19/12/12 15:26:01 INFO mapred.Task: Final Counters for attempt_local515344090_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=479854\n",
      "\t\tFILE: Number of bytes written=518067\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=85\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tShuffled Maps =5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=5\n",
      "\t\tGC time elapsed (ms)=22\n",
      "\t\tTotal committed heap usage (bytes)=531103744\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=80\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local515344090_0001_r_000000_0\n",
      "19/12/12 15:26:01 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "19/12/12 15:26:02 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/12/12 15:26:02 INFO mapreduce.Job: Job job_local515344090_0001 completed successfully\n",
      "19/12/12 15:26:02 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2248131\n",
      "\t\tFILE: Number of bytes written=3107207\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1966\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=53\n",
      "\t\tMap output materialized bytes=85\n",
      "\t\tInput split bytes=510\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=85\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=5\n",
      "\t\tGC time elapsed (ms)=47\n",
      "\t\tTotal committed heap usage (bytes)=2440036352\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=341738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=80\n",
      "19/12/12 15:26:02 INFO streaming.StreamJob: Output directory: output\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "username=\"Alex Martin\"\n",
    "User=\"./mapper.py $username\"\n",
    "#Hadoop command to run the map reduce.\n",
    "rm -rf output\n",
    "hadoop-standalone-mode.sh\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper.py,reducer.py \\\n",
    "-input Youtube01-Psy.csv,Youtube02-KatyPerry.csv,Youtube03-LMFAO.csv,Youtube04-Eminem.csv,Youtube05-Shakira.csv \\\n",
    "-mapper \"$User\" \\\n",
    "-reducer ./reducer.py \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#John Smith\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]\n",
    "#Jane Doe\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
